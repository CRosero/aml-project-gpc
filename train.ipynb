{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CRosero/aml-project/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the dataset from drive.\n",
        "( You can find the zipped folder [here](https://drive.google.com/file/d/1XsRmyQYHfgRFJCOueXpJ37yyOCrKHO-W/view?usp=sharing))"
      ],
      "metadata": {
        "id": "Y9D12pC0R_eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/gdrive/')\n",
        "data_path = \"/content/data\"\n",
        "\n",
        "\n",
        "if not os.path.isfile('/content/data.zip'):\n",
        "  !gdown --id 1XsRmyQYHfgRFJCOueXpJ37yyOCrKHO-W # 3-5 min\n",
        "  !jar xf  \"/content/data.zip\"\n",
        "\n",
        "if not os.path.isdir('/content/data'):\n",
        "  print(\"Dataset doesn't exist\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YOzT4IA9ZnnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515dbced-c235-4665-dc76-1f56d756a0f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive/; to attempt to forcibly remount, call drive.mount(\"/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cloning the repository from github"
      ],
      "metadata": {
        "id": "e1nqqrU5SIBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "repo_path = \"/content/cloned-repo\"\n",
        "if not os.path.isdir(repo_path):\n",
        "  !git clone -l -s git://github.com/CRosero/aml-project.git cloned-repo\n",
        "  %cd cloned-repo\n",
        "else:\n",
        "  print(\"Repository already cloned\")\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uzIXW9Z5Kl4",
        "outputId": "503656fa-be51-4996-d98b-4e7f09288778"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository already cloned\n",
            "/content/cloned-repo\n",
            "dataset     eval.py  model\t  README.md  train.ipynb  utils.py\n",
            "eval.ipynb  loss.py  __pycache__  runs\t     train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "A4np6uwUgDMW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QYHTsZf6SkxK"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from model.build_BiSeNet import BiSeNet\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from utils import poly_lr_scheduler\n",
        "from utils import reverse_one_hot, compute_global_accuracy, fast_hist, per_class_iu\n",
        "from loss import DiceLoss\n",
        "import torch.cuda.amp as amp\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import torchvision\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from torch.utils import data\n",
        "from PIL import Image\n",
        "import json\n",
        "# Dataset class:\n",
        "from dataset.cityscapesDataSet import cityscapesDataSet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "n9TWPNCay2Md"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## -- VALIDATION --\n",
        "\n",
        "def val(args, model, dataloader):\n",
        "    print('start val!')\n",
        "    # label_info = get_label_info(csv_path)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        precision_record = []\n",
        "        hist = np.zeros((args.num_classes, args.num_classes))\n",
        "        for i, (data, label) in enumerate(dataloader):\n",
        "            label = label.type(torch.LongTensor)\n",
        "            \n",
        "            if torch.cuda.is_available() and args.use_gpu:\n",
        "                data = data.cuda()\n",
        "                label = label.cuda()\n",
        "\n",
        "            # get RGB predict image\n",
        "            predict = model(data).squeeze()\n",
        "            predict = reverse_one_hot(predict)\n",
        "            predict = np.array(predict.cpu())\n",
        "\n",
        "            # get RGB label image\n",
        "            label = label.squeeze()\n",
        "            label = np.array(label.cpu())\n",
        "\n",
        "            # compute per pixel accuracy\n",
        "            precision = compute_global_accuracy(predict, label)\n",
        "            hist += fast_hist(label.flatten(), predict.flatten(), args.num_classes)\n",
        "\n",
        "            # there is no need to transform the one-hot array to visual RGB array\n",
        "            # predict = colour_code_segmentation(np.array(predict), label_info)\n",
        "            # label = colour_code_segmentation(np.array(label), label_info)\n",
        "            precision_record.append(precision)\n",
        "        \n",
        "        precision = np.mean(precision_record)\n",
        "        # miou = np.mean(per_class_iu(hist))\n",
        "        miou_list = per_class_iu(hist)[:-1]\n",
        "        # miou_dict, miou = cal_miou(miou_list, csv_path)\n",
        "        miou = np.mean(miou_list)\n",
        "        print('precision per pixel for test: %.3f' % precision)\n",
        "        print('mIoU for validation: %.3f' % miou)\n",
        "        # miou_str = ''\n",
        "        # for key in miou_dict:\n",
        "        #     miou_str += '{}:{},\\n'.format(key, miou_dict[key])\n",
        "        # print('mIoU for each class:')\n",
        "        # print(miou_str)\n",
        "        return precision, miou"
      ],
      "metadata": {
        "id": "gnVsI55NSpcW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## -- TRAINING --\n",
        "\n",
        "def train(args, model, optimizer, dataloader_train, dataloader_val):\n",
        "    writer = SummaryWriter(comment=''.format(args.optimizer, args.context_path))\n",
        "\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    if args.loss == 'dice':\n",
        "        loss_func = DiceLoss()\n",
        "    elif args.loss == 'crossentropy':\n",
        "        loss_func = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
        "    \n",
        "    max_miou = 0\n",
        "    step = 0\n",
        "    \n",
        "    for epoch in range(args.num_epochs):\n",
        "        lr = poly_lr_scheduler(optimizer, args.learning_rate, iter=epoch, max_iter=args.num_epochs)\n",
        "        model.train()\n",
        "        tq = tqdm(total=len(dataloader_train) * args.batch_size)\n",
        "        tq.set_description('epoch %d, lr %f' % (epoch, lr))\n",
        "        loss_record = []\n",
        "        for i, (data, label) in enumerate(dataloader_train):\n",
        "            if torch.cuda.is_available() and args.use_gpu:\n",
        "                data = data.cuda()\n",
        "                label = label.long().cuda()\n",
        "  \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with amp.autocast():\n",
        "                output, output_sup1, output_sup2 = model(data)\n",
        "                loss1 = loss_func(output, label)\n",
        "                loss2 = loss_func(output_sup1, label)\n",
        "                loss3 = loss_func(output_sup2, label)\n",
        "                loss = loss1 + loss2 + loss3\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "            tq.update(args.batch_size)\n",
        "            #tq.set_postfix(loss='%.6f' % loss)\n",
        "            step += 1\n",
        "            writer.add_scalar('loss_step', loss, step)\n",
        "            loss_record.append(loss.item())\n",
        "            \n",
        "        tq.close()\n",
        "        loss_train_mean = np.mean(loss_record)\n",
        "        writer.add_scalar('epoch/loss_epoch_train', float(loss_train_mean), epoch)\n",
        "        print('loss for train : %f' % (loss_train_mean))\n",
        "        \n",
        "        if epoch % args.checkpoint_step == 0 and epoch != 0:\n",
        "            import os\n",
        "            if not os.path.isdir(args.save_model_path):\n",
        "                os.mkdir(args.save_model_path)\n",
        "            torch.save(model.module.state_dict(),\n",
        "                       os.path.join(args.save_model_path, 'latest_dice_loss.pth'))\n",
        "\n",
        "        if epoch % args.validation_step == 0 and epoch != 0:\n",
        "            precision, miou = val(args, model, dataloader_val)\n",
        "            if miou > max_miou:\n",
        "                max_miou = miou\n",
        "                import os \n",
        "                os.makedirs(args.save_model_path, exist_ok=True)\n",
        "                torch.save(model.module.state_dict(),\n",
        "                           os.path.join(args.save_model_path, 'best_dice_loss.pth'))\n",
        "            writer.add_scalar('epoch/precision_val', precision, epoch)\n",
        "            writer.add_scalar('epoch/miou val', miou, epoch)"
      ],
      "metadata": {
        "id": "quVpMD_PSwJS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(params):\n",
        "    # basic parameters\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--num_epochs', type=int, default=300, help='Number of epochs to train for')\n",
        "    parser.add_argument('--epoch_start_i', type=int, default=0, help='Start counting epochs from this number')\n",
        "    parser.add_argument('--checkpoint_step', type=int, default=10, help='How often to save checkpoints (epochs)')\n",
        "    parser.add_argument('--validation_step', type=int, default=10, help='How often to perform validation (epochs)')\n",
        "    parser.add_argument('--dataset', type=str, default=\"Cityscapes\", help='Dataset you are using.')\n",
        "    parser.add_argument('--crop_height', type=int, default=720, help='Height of cropped/resized input image to network')\n",
        "    parser.add_argument('--crop_width', type=int, default=960, help='Width of cropped/resized input image to network')\n",
        "    parser.add_argument('--batch_size', type=int, default=32, help='Number of images in each batch')\n",
        "    parser.add_argument(\"--iter-size\", type=int, default=1, help=\"Accumulate gradients for ITER_SIZE iterations.\")\n",
        "    parser.add_argument('--context_path', type=str, default=\"resnet101\",\n",
        "                        help='The context path model you are using, resnet18, resnet101.')\n",
        "    parser.add_argument('--learning_rate', type=float, default=0.01, help='learning rate used for train')\n",
        "    parser.add_argument('--data', type=str, default='content/data', help='path of training data')\n",
        "    #parser.add_argument(\"--data-list\", type=str, default='/gdrive/MyDrive/data/Cityscapes/train.txt', help=\"Path to the file listing the images in the source dataset.\")\n",
        "    #parser.add_argument(\"--data-list-val\", type=str, default='/gdrive/MyDrive/data/Cityscapes/val.txt', help=\"Path to the file listing the image in the test subset.\")\n",
        "    parser.add_argument('--num_workers', type=int, default=4, help='num of workers')\n",
        "    parser.add_argument('--num_classes', type=int, default=32, help='num of object classes (with void)')\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=250000, help=\"Number of training steps.\")\n",
        "    parser.add_argument('--cuda', type=str, default='0', help='GPU ids used for training')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='whether to user gpu for training')\n",
        "    parser.add_argument('--pretrained_model_path', type=str, default=None, help='path to pretrained model')\n",
        "    parser.add_argument('--save_model_path', type=str, default=None, help='path to save model')\n",
        "    parser.add_argument('--optimizer', type=str, default='rmsprop', help='optimizer, support rmsprop, sgd, adam')\n",
        "    parser.add_argument('--loss', type=str, default='crossentropy', help='loss function, dice or crossentropy')\n",
        "    parser.add_argument(\"--random-scale\", action=\"store_true\", help=\"Whether to randomly scale the inputs during the training.\")\n",
        "    parser.add_argument(\"--random-mirror\", action=\"store_true\", help=\"Whether to randomly mirror the inputs during the training.\")\n",
        "    parser.add_argument(\"--set-type\", type=str, default='train', help=\"choose adaptation set.\")\n",
        "\n",
        "    args = parser.parse_args(params)\n",
        "\n",
        "    # create dataset and dataloader\n",
        "    data_root_path = os.path.join(args.data, args.dataset) # /content/data/Cityscapes\n",
        "    train_path = os.path.join(data_root_path, \"train.txt\") # /content/data/Cityscapes/train.txt\n",
        "    val_path = os.path.join(data_root_path, \"val.txt\")   # /content/data/Cityscapes/val.txt\n",
        "    info_path = os.path.join(args.data, args.dataset, \"info.json\") # /content/data/Cityscapes/info.json \n",
        "    \n",
        "    # preprocessing informations:\n",
        "    input_size = (int(args.crop_height), int(args.crop_width))\n",
        "    f = open(info_path)\n",
        "    info = json.load(f)\n",
        "    img_mean = info[\"mean\"] # [73.15835921071155, 82.90891754262586, 72.39239876194159]  -> TODO: ask the tutor\n",
        "    img_mean = np.array(img_mean, dtype=np.float32)\n",
        "    #img_mean = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "    #img_mean=(128, 128, 128)\n",
        "\n",
        "    \n",
        "    # create dataloaders\n",
        "    train_dataset = cityscapesDataSet(root=data_root_path,\n",
        "                                      list_path = train_path,\n",
        "                                      info_json = info,\n",
        "                                      crop_size=input_size,\n",
        "                                      scale=args.random_scale, \n",
        "                                      mirror=args.random_mirror, \n",
        "                                      mean=img_mean)\n",
        "   \n",
        "    \n",
        "    val_dataset = cityscapesDataSet(root=data_root_path,\n",
        "                                    list_path = val_path,\n",
        "                                    info_json = info,\n",
        "                                    crop_size=input_size,\n",
        "                                    scale=False,\n",
        "                                    mirror=args.random_mirror, \n",
        "                                    mean=img_mean)\n",
        "    \n",
        "    print(f'train_dataset: {len(train_dataset)}')\n",
        "    print(f'val_dataset: {len(val_dataset)}')\n",
        "    image, label = train_dataset[0]\n",
        "    print(f'images shape: {image.shape}')\n",
        "    print(f'label shape: {label.shape}')\n",
        "    \n",
        "    # Define dataloaders\n",
        "    dataloader_train = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
        "    # (batch size for dataloader_val must be 1)\n",
        "    dataloader_val = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
        "    \n",
        "    # build model\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = args.cuda\n",
        "    \n",
        "    model = BiSeNet(args.num_classes, args.context_path)\n",
        "    \n",
        "    if torch.cuda.is_available() and args.use_gpu:\n",
        "        model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "    # build optimizer\n",
        "    if args.optimizer == 'rmsprop':\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), args.learning_rate)\n",
        "    elif args.optimizer == 'sgd':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), args.learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "    elif args.optimizer == 'adam':\n",
        "        optimizer = torch.optim.Adam(model.parameters(), args.learning_rate)\n",
        "    else:  # rmsprop\n",
        "        print('not supported optimizer \\n')\n",
        "        return None\n",
        "\n",
        "    # load pretrained model if exists\n",
        "    if args.pretrained_model_path is not None:\n",
        "        print('load model from %s ...' % args.pretrained_model_path)\n",
        "        model.module.load_state_dict(torch.load(args.pretrained_model_path))\n",
        "        print('Done!')\n",
        "\n",
        "    # train\n",
        "    train(args, model, optimizer, dataloader_train, dataloader_val)\n",
        "\n",
        "    val(args, model, dataloader_val)\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "8X0hpXG5S0ta"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "XbPSPiAYzYJ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "outputId": "71225f6d-7a86-4979-b845-33b5705aee37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 1635), started 0:04:02 ago. (Use '!kill 1635' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    params = [\n",
        "        '--num_epochs', '50',\n",
        "        '--learning_rate', '2.5e-2',\n",
        "        '--data', data_path,\n",
        "        '--num_workers', '4',\n",
        "        '--num_classes', '19',\n",
        "        '--cuda', '0',\n",
        "        '--batch_size', '2',\n",
        "        '--save_model_path', '/gdrive/MyDrive/Project_AML/Models/checkpoints_101_adam',\n",
        "        '--context_path', 'resnet101',  # set resnet18 or resnet101, only support resnet18 and resnet101\n",
        "        '--optimizer', 'adam',\n",
        "\n",
        "    ]\n",
        "    main(params)"
      ],
      "metadata": {
        "id": "ryuEeQcMS4R5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1a88eb-7fc2-4939-ccbc-5e402d6c64c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset: 500\n",
            "val_dataset: 250\n",
            "images shape: (3, 960, 720)\n",
            "label shape: (960, 720)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 0, lr 0.025000:  72%|███████▏  | 362/500 [11:47<04:29,  1.95s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_summary()\n",
        "#torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "74xLh4HqXQT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}