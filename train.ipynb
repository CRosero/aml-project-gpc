{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/CRosero/aml-project/blob/master/train.ipynb",
      "authorship_tag": "ABX9TyM24IvR0fp4qf/y3PtDLrIz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CRosero/aml-project/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s git://github.com/CRosero/aml-project.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uzIXW9Z5Kl4",
        "outputId": "47f2a1cd-3a71-4f25-9f64-0d503cb44276"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cloned-repo' already exists and is not an empty directory.\n",
            "/content/cloned-repo\n",
            "dataset     eval.py  model\t  README.md    train.py\n",
            "eval.ipynb  loss.py  __pycache__  train.ipynb  utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')"
      ],
      "metadata": {
        "id": "YOzT4IA9ZnnX",
        "outputId": "41fe3c0d-83e3-4916-874a-412f107fb6d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl4HacpJ8ckh",
        "outputId": "3b4c46a9-7b1c-4450-c911-17957ffaa884"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QYHTsZf6SkxK"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from model.build_BiSeNet import BiSeNet\n",
        "import torch\n",
        "from tensorboardX import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from utils import poly_lr_scheduler\n",
        "from utils import reverse_one_hot, compute_global_accuracy, fast_hist, per_class_iu\n",
        "from loss import DiceLoss\n",
        "import torch.cuda.amp as amp\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class cityscapesDataSet(data.Dataset):\n",
        "    def __init__(self, root, list_path, max_iters=None, crop_size=(321, 321), mean=(128, 128, 128), scale=True, mirror=True, ignore_label=255):\n",
        "        self.root = root\n",
        "        self.list_path = list_path\n",
        "        self.crop_size = crop_size\n",
        "        self.scale = scale\n",
        "        self.ignore_label = ignore_label\n",
        "        self.mean = mean\n",
        "        self.is_mirror = mirror\n",
        "        # self.mean_bgr = np.array([104.00698793, 116.66876762, 122.67891434])\n",
        "        self.img_ids = [i_id.strip() for i_id in open(list_path)]\n",
        "        if not max_iters==None:\n",
        "            self.img_ids = self.img_ids * int(np.ceil(float(max_iters) / len(self.img_ids)))\n",
        "        self.files = []\n",
        "        self.set = set\n",
        "        # for split in [\"train\", \"trainval\", \"val\"]:\n",
        "        for name in self.img_ids:\n",
        "            # Replace 'train' folder with 'images' folder and  \n",
        "            # remove reference to city folder for images provided subset of the dataset\n",
        "            img_file = osp.join(self.root[0].replace('train', 'images'), name.split(\"/\", 1)[1])\n",
        "            # Replace 'train' folder with 'labels' folder and  \n",
        "            # remove reference to city folder for images provided subset of the dataset\n",
        "            # rename file to be that of the label\n",
        "            label_file = osp.join(self.root[0].replace('train', 'labels'), \n",
        "                                  name.split(\"/\", 1)[1].replace('leftImg8bit', 'gtFine_labelIds'))\n",
        "            self.files.append({\n",
        "                \"img\": img_file,\n",
        "                \"label\":label_file,\n",
        "                \"name\": name\n",
        "            })\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        datafiles = self.files[index]\n",
        "\n",
        "        image = Image.open(datafiles[\"img\"]).convert('RGB')\n",
        "        label = Image.open(datafiles[\"label\"])\n",
        "        name = datafiles[\"name\"]\n",
        "\n",
        "        # resize\n",
        "        image = image.resize(self.crop_size, Image.BILINEAR)\n",
        "        label = label.resize(self.crop_size, Image.NEAREST)\n",
        "\n",
        "        image = np.asarray(image, np.float32)\n",
        "        label = np.asarray(label, np.float32)\n",
        "\n",
        "        # re-assign labels to match the format of Cityscapes\n",
        "        label_copy = 255 * np.ones(label.shape, dtype=np.float32)\n",
        "        for k, v in self.id_to_trainid.items():\n",
        "            label_copy[label == k] = v\n",
        "\n",
        "        size = image.shape\n",
        "        image = image[:, :, ::-1]  # change to BGR\n",
        "        image -= self.mean\n",
        "        image = image.transpose((2, 0, 1))\n",
        "\n",
        "        return image.copy(), label_copy.copy(), np.array(size), name\n"
      ],
      "metadata": {
        "id": "_Iu4E8mdbpGu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(args, model, dataloader):\n",
        "    print('start val!')\n",
        "    # label_info = get_label_info(csv_path)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        precision_record = []\n",
        "        hist = np.zeros((args.num_classes, args.num_classes))\n",
        "        for i, (data, label) in enumerate(dataloader):\n",
        "            label = label.type(torch.LongTensor)\n",
        "            data = data.cuda()\n",
        "            label = label.long().cuda()\n",
        "\n",
        "            # get RGB predict image\n",
        "            predict = model(data).squeeze()\n",
        "            predict = reverse_one_hot(predict)\n",
        "            predict = np.array(predict.cpu())\n",
        "\n",
        "            # get RGB label image\n",
        "            label = label.squeeze()\n",
        "            if args.loss == 'dice':\n",
        "                label = reverse_one_hot(label)\n",
        "            label = np.array(label.cpu())\n",
        "\n",
        "            # compute per pixel accuracy\n",
        "            precision = compute_global_accuracy(predict, label)\n",
        "            hist += fast_hist(label.flatten(), predict.flatten(), args.num_classes)\n",
        "\n",
        "            # there is no need to transform the one-hot array to visual RGB array\n",
        "            # predict = colour_code_segmentation(np.array(predict), label_info)\n",
        "            # label = colour_code_segmentation(np.array(label), label_info)\n",
        "            precision_record.append(precision)\n",
        "        \n",
        "        precision = np.mean(precision_record)\n",
        "        # miou = np.mean(per_class_iu(hist))\n",
        "        miou_list = per_class_iu(hist)[:-1]\n",
        "        # miou_dict, miou = cal_miou(miou_list, csv_path)\n",
        "        miou = np.mean(miou_list)\n",
        "        print('precision per pixel for test: %.3f' % precision)\n",
        "        print('mIoU for validation: %.3f' % miou)\n",
        "        # miou_str = ''\n",
        "        # for key in miou_dict:\n",
        "        #     miou_str += '{}:{},\\n'.format(key, miou_dict[key])\n",
        "        # print('mIoU for each class:')\n",
        "        # print(miou_str)\n",
        "        return precision, miou"
      ],
      "metadata": {
        "id": "gnVsI55NSpcW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, model, optimizer, dataloader_train, dataloader_val):\n",
        "    writer = SummaryWriter(comment=''.format(args.optimizer, args.context_path))\n",
        "\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    if args.loss == 'dice':\n",
        "        loss_func = DiceLoss()\n",
        "    elif args.loss == 'crossentropy':\n",
        "        loss_func = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
        "    max_miou = 0\n",
        "    step = 0\n",
        "    for epoch in range(args.num_epochs):\n",
        "        lr = poly_lr_scheduler(optimizer, args.learning_rate, iter=epoch, max_iter=args.num_epochs)\n",
        "        model.train()\n",
        "        tq = tqdm(total=len(dataloader_train) * args.batch_size)\n",
        "        tq.set_description('epoch %d, lr %f' % (epoch, lr))\n",
        "        loss_record = []\n",
        "        for i, (data, label) in enumerate(dataloader_train):\n",
        "            \n",
        "            data = data.cuda()\n",
        "            label = label.long().cuda()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with amp.autocast():\n",
        "                output, output_sup1, output_sup2 = model(data)\n",
        "                loss1 = loss_func(output, label)\n",
        "                loss2 = loss_func(output_sup1, label)\n",
        "                loss3 = loss_func(output_sup2, label)\n",
        "                loss = loss1 + loss2 + loss3\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "            tq.update(args.batch_size)\n",
        "            tq.set_postfix(loss='%.6f' % loss)\n",
        "            step += 1\n",
        "            writer.add_scalar('loss_step', loss, step)\n",
        "            loss_record.append(loss.item())\n",
        "        tq.close()\n",
        "        loss_train_mean = np.mean(loss_record)\n",
        "        writer.add_scalar('epoch/loss_epoch_train', float(loss_train_mean), epoch)\n",
        "        print('loss for train : %f' % (loss_train_mean))\n",
        "        if epoch % args.checkpoint_step == 0 and epoch != 0:\n",
        "            import os\n",
        "            if not os.path.isdir(args.save_model_path):\n",
        "                os.mkdir(args.save_model_path)\n",
        "            torch.save(model.module.state_dict(),\n",
        "                       os.path.join(args.save_model_path, 'latest_dice_loss.pth'))\n",
        "\n",
        "        if epoch % args.validation_step == 0 and epoch != 0:\n",
        "            precision, miou = val(args, model, dataloader_val)\n",
        "            if miou > max_miou:\n",
        "                max_miou = miou\n",
        "                import os \n",
        "                os.makedirs(args.save_model_path, exist_ok=True)\n",
        "                torch.save(model.module.state_dict(),\n",
        "                           os.path.join(args.save_model_path, 'best_dice_loss.pth'))\n",
        "            writer.add_scalar('epoch/precision_val', precision, epoch)\n",
        "            writer.add_scalar('epoch/miou val', miou, epoch)"
      ],
      "metadata": {
        "id": "quVpMD_PSwJS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(params):\n",
        "    # basic parameters\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--num_epochs', type=int, default=300, help='Number of epochs to train for')\n",
        "    parser.add_argument('--epoch_start_i', type=int, default=0, help='Start counting epochs from this number')\n",
        "    parser.add_argument('--checkpoint_step', type=int, default=10, help='How often to save checkpoints (epochs)')\n",
        "    parser.add_argument('--validation_step', type=int, default=10, help='How often to perform validation (epochs)')\n",
        "    parser.add_argument('--dataset', type=str, default=\"Cityscapes\", help='Dataset you are using.')\n",
        "    parser.add_argument('--crop_height', type=int, default=720, help='Height of cropped/resized input image to network')\n",
        "    parser.add_argument('--crop_width', type=int, default=960, help='Width of cropped/resized input image to network')\n",
        "    parser.add_argument('--batch_size', type=int, default=32, help='Number of images in each batch')\n",
        "    parser.add_argument(\"--iter-size\", type=int, default=1, help=\"Accumulate gradients for ITER_SIZE iterations.\")\n",
        "    parser.add_argument('--context_path', type=str, default=\"resnet101\",\n",
        "                        help='The context path model you are using, resnet18, resnet101.')\n",
        "    parser.add_argument('--learning_rate', type=float, default=0.01, help='learning rate used for train')\n",
        "    parser.add_argument('--data', type=str, default='', help='path of training data')\n",
        "    parser.add_argument(\"--data-list\", type=str, default='/gdrive/MyDrive/data/Cityscapes/train.txt', help=\"Path to the file listing the images in the source dataset.\")\n",
        "    parser.add_argument('--num_workers', type=int, default=4, help='num of workers')\n",
        "    parser.add_argument('--num_classes', type=int, default=32, help='num of object classes (with void)')\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=250000, help=\"Number of training steps.\")\n",
        "    parser.add_argument('--cuda', type=str, default='0', help='GPU ids used for training')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='whether to user gpu for training')\n",
        "    parser.add_argument('--pretrained_model_path', type=str, default=None, help='path to pretrained model')\n",
        "    parser.add_argument('--save_model_path', type=str, default=None, help='path to save model')\n",
        "    parser.add_argument('--optimizer', type=str, default='rmsprop', help='optimizer, support rmsprop, sgd, adam')\n",
        "    parser.add_argument('--loss', type=str, default='crossentropy', help='loss function, dice or crossentropy')\n",
        "    parser.add_argument(\"--random-scale\", action=\"store_true\", help=\"Whether to randomly scale the inputs during the training.\")\n",
        "    parser.add_argument(\"--random-mirror\", action=\"store_true\", help=\"Whether to randomly mirror the inputs during the training.\")\n",
        "    parser.add_argument(\"--set\", type=str, default='train', help=\"choose adaptation set.\")\n",
        "\n",
        "    args = parser.parse_args(params)\n",
        "\n",
        "    input_size = ('{height}, {width}').format(height = args.crop_height, width = args.crop_width)\n",
        "    #img_mean = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "    img_mean=(128, 128, 128)\n",
        "\n",
        "    # create dataset and dataloader\n",
        "    train_path = [os.path.join(args.data, 'train'), os.path.join(args.data, 'val')]\n",
        "    train_label_path = [os.path.join(args.data, 'train_labels'), os.path.join(args.data, 'val_labels')]\n",
        "    test_path = os.path.join(args.data, 'test')\n",
        "    test_label_path = os.path.join(args.data, 'test_labels')\n",
        "    csv_path = os.path.join(args.data, 'class_dict.csv')\n",
        "    \n",
        "    # Define dataloaders\n",
        "    dataloader_train = DataLoader(cityscapesDataSet(train_path, args.data_list, \n",
        "                    max_iters=args.num_steps * args.iter_size * args.batch_size,\n",
        "                    crop_size=input_size,\n",
        "                    scale=args.random_scale, mirror=args.random_mirror, \n",
        "                    mean=img_mean),\n",
        "        batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
        "    \n",
        "    dataloader_val = DataLoader(cityscapesDataSet(test_path, args.data_list_target,\n",
        "                  max_iters=args.num_steps * args.iter_size * args.batch_size,\n",
        "                  crop_size=input_size,\n",
        "                  scale=False, mirror=args.random_mirror, \n",
        "                  mean=img_mean, set=args.set),\n",
        "        batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
        "    \n",
        "    # build model\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = args.cuda\n",
        "    model = BiSeNet(args.num_classes, args.context_path)\n",
        "    if torch.cuda.is_available() and args.use_gpu:\n",
        "        model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "    # build optimizer\n",
        "    if args.optimizer == 'rmsprop':\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), args.learning_rate)\n",
        "    elif args.optimizer == 'sgd':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), args.learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "    elif args.optimizer == 'adam':\n",
        "        optimizer = torch.optim.Adam(model.parameters(), args.learning_rate)\n",
        "    else:  # rmsprop\n",
        "        print('not supported optimizer \\n')\n",
        "        return None\n",
        "\n",
        "    # load pretrained model if exists\n",
        "    if args.pretrained_model_path is not None:\n",
        "        print('load model from %s ...' % args.pretrained_model_path)\n",
        "        model.module.load_state_dict(torch.load(args.pretrained_model_path))\n",
        "        print('Done!')\n",
        "\n",
        "    # train\n",
        "    train(args, model, optimizer, dataloader_train, dataloader_val)\n",
        "\n",
        "    # val(args, model, dataloader_val, csv_path)"
      ],
      "metadata": {
        "id": "8X0hpXG5S0ta"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.path.isdir('/gdrive/MyDrive/data/Cityscapes/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAThi-RKtFqV",
        "outputId": "cab39483-0959-4496-fbb9-00a36d086e6d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    params = [\n",
        "        '--num_epochs', '50',\n",
        "        '--learning_rate', '2.5e-2',\n",
        "        '--data', '/gdrive/MyDrive/data/Cityscapes',\n",
        "        '--num_workers', '8',\n",
        "        '--num_classes', '19',\n",
        "        '--cuda', '0',\n",
        "        '--batch_size', '8',\n",
        "        '--save_model_path', '/gdrive/MyDrive/Project_AML/Models/checkpoints_101_adam',\n",
        "        '--context_path', 'resnet101',  # set resnet18 or resnet101, only support resnet18 and resnet101\n",
        "        '--optimizer', 'adam',\n",
        "\n",
        "    ]\n",
        "    main(params)"
      ],
      "metadata": {
        "id": "ryuEeQcMS4R5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "0cc5cc69-3dcb-4b33-b031-8779c3a82e63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f7f070506051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     ]\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-d194fab75630>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     50\u001b[0m         batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     dataloader_val = DataLoader(cityscapesDataSet(test_path, args.data_list_target,\n\u001b[0m\u001b[1;32m     53\u001b[0m                   \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                   \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'data_list_target'"
          ]
        }
      ]
    }
  ]
}