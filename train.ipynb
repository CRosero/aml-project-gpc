{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/CRosero/aml-project/blob/master/train.ipynb",
      "authorship_tag": "ABX9TyMQ+D+CsNOcQCA+S3zMT6gl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CRosero/aml-project/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')"
      ],
      "metadata": {
        "id": "YOzT4IA9ZnnX",
        "outputId": "b8ffd3e7-946b-43dd-bde4-1dc9f79ad4f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s git://github.com/CRosero/aml-project.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uzIXW9Z5Kl4",
        "outputId": "1c2431fd-a74d-489d-b99f-e67c9884e8bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 82 (delta 19), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Receiving objects: 100% (82/82), 50.06 KiB | 1.28 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "/content/cloned-repo\n",
            "dataset     eval.py  model\ttrain.ipynb  utils.py\n",
            "eval.ipynb  loss.py  README.md\ttrain.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl4HacpJ8ckh",
        "outputId": "62861ac8-42bf-4333-e5e4-8f2755df9028"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyy7urSmpK-X",
        "outputId": "58134335-ad43-43e9-9f78-d66d296f2f05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cloned-repo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QYHTsZf6SkxK"
      },
      "outputs": [],
      "source": [
        "#import sys\n",
        "#sys.path.append('/cloned-repo/model')\n",
        "#print(sys.path)\n",
        "import argparse\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from model.build_BiSeNet import BiSeNet\n",
        "import torch\n",
        "from tensorboardX import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from utils import poly_lr_scheduler\n",
        "from utils import reverse_one_hot, compute_global_accuracy, fast_hist, per_class_iu\n",
        "from loss import DiceLoss\n",
        "import torch.cuda.amp as amp\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import torchvision\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from torch.utils import data\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class cityscapesDataSet(data.Dataset):\n",
        "    def __init__(self, root, list_path, max_iters=None, crop_size=(321, 321), mean=(128, 128, 128), scale=True, mirror=True, ignore_label=255):\n",
        "        self.root = root\n",
        "        self.list_path = list_path\n",
        "        self.crop_size = tuple(int(num) for num in crop_size.replace('(', '').replace(')', '').replace('...', '').split(', '))\n",
        "        self.scale = scale\n",
        "        self.ignore_label = ignore_label\n",
        "        self.mean = mean\n",
        "        self.is_mirror = mirror\n",
        "        # self.mean_bgr = np.array([104.00698793, 116.66876762, 122.67891434])\n",
        "        self.img_ids = [i_id.strip() for i_id in open(list_path)]\n",
        "        if not max_iters==None:\n",
        "            self.img_ids = self.img_ids * int(np.ceil(float(max_iters) / len(self.img_ids)))\n",
        "        self.files = []\n",
        "        # for split in [\"train\", \"trainval\", \"val\"]:\n",
        "        for name in self.img_ids:\n",
        "            # Replace 'train' folder with 'images' folder and  \n",
        "            # remove reference to city folder for images provided subset of the dataset\n",
        "            img_file = osp.join(self.root[0].replace('train', 'images'), name.split(\"/\", 1)[1])\n",
        "            # Replace 'train' folder with 'labels' folder and  \n",
        "            # remove reference to city folder for images provided subset of the dataset\n",
        "            # rename file to be that of the label\n",
        "            label_file = osp.join(self.root[0].replace('train', 'labels'), \n",
        "                                  name.split(\"/\", 1)[1].replace('leftImg8bit', 'gtFine_labelIds'))\n",
        "            self.files.append({\n",
        "                \"img\": img_file,\n",
        "                \"label\":label_file,\n",
        "                \"name\": name\n",
        "            })\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        datafiles = self.files[index]\n",
        "        \n",
        "        image = Image.open(datafiles[\"img\"]).convert('RGB')\n",
        "        label = Image.open(datafiles[\"label\"])\n",
        "        name = datafiles[\"name\"]\n",
        "\n",
        "        # resize\n",
        "        print(f'image before resize: {image}')\n",
        "        print(f'type crop_size: {type(self.crop_size)}')\n",
        "        image = image.resize(self.crop_size, Image.BILINEAR)\n",
        "        print(f'image after resize: {image}')\n",
        "        print(f'label before resize: {label}')\n",
        "        label = label.resize(self.crop_size, Image.NEAREST)\n",
        "        print(f'label after resize: {label}')\n",
        "\n",
        "        image = np.asarray(image, np.float32)\n",
        "        print(f'image as array: {image}')\n",
        "        label = np.asarray(label, np.float32)\n",
        "        print(f'label as array: {label}')\n",
        "\n",
        "        # re-assign labels to match the format of Cityscapes\n",
        "        label_copy = 255 * np.ones(label.shape, dtype=np.float32)\n",
        "        for k, v in self.id_to_trainid.items():\n",
        "            label_copy[label == k] = v\n",
        "\n",
        "        size = image.shape\n",
        "        image = image[:, :, ::-1]  # change to BGR\n",
        "        image -= self.mean\n",
        "        image = image.transpose((2, 0, 1))\n",
        "\n",
        "        return image.copy(), label_copy.copy(), np.array(size), name\n"
      ],
      "metadata": {
        "id": "_Iu4E8mdbpGu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(args, model, dataloader):\n",
        "    print('start val!')\n",
        "    # label_info = get_label_info(csv_path)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        precision_record = []\n",
        "        hist = np.zeros((args.num_classes, args.num_classes))\n",
        "        for i, (data, label) in enumerate(dataloader):\n",
        "            label = label.type(torch.LongTensor)\n",
        "            data = data.cuda()\n",
        "            label = label.long().cuda()\n",
        "\n",
        "            # get RGB predict image\n",
        "            predict = model(data).squeeze()\n",
        "            predict = reverse_one_hot(predict)\n",
        "            predict = np.array(predict.cpu())\n",
        "\n",
        "            # get RGB label image\n",
        "            label = label.squeeze()\n",
        "            if args.loss == 'dice':\n",
        "                label = reverse_one_hot(label)\n",
        "            label = np.array(label.cpu())\n",
        "\n",
        "            # compute per pixel accuracy\n",
        "            precision = compute_global_accuracy(predict, label)\n",
        "            hist += fast_hist(label.flatten(), predict.flatten(), args.num_classes)\n",
        "\n",
        "            # there is no need to transform the one-hot array to visual RGB array\n",
        "            # predict = colour_code_segmentation(np.array(predict), label_info)\n",
        "            # label = colour_code_segmentation(np.array(label), label_info)\n",
        "            precision_record.append(precision)\n",
        "        \n",
        "        precision = np.mean(precision_record)\n",
        "        # miou = np.mean(per_class_iu(hist))\n",
        "        miou_list = per_class_iu(hist)[:-1]\n",
        "        # miou_dict, miou = cal_miou(miou_list, csv_path)\n",
        "        miou = np.mean(miou_list)\n",
        "        print('precision per pixel for test: %.3f' % precision)\n",
        "        print('mIoU for validation: %.3f' % miou)\n",
        "        # miou_str = ''\n",
        "        # for key in miou_dict:\n",
        "        #     miou_str += '{}:{},\\n'.format(key, miou_dict[key])\n",
        "        # print('mIoU for each class:')\n",
        "        # print(miou_str)\n",
        "        return precision, miou"
      ],
      "metadata": {
        "id": "gnVsI55NSpcW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, model, optimizer, dataloader_train, dataloader_val):\n",
        "    writer = SummaryWriter(comment=''.format(args.optimizer, args.context_path))\n",
        "\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    if args.loss == 'dice':\n",
        "        loss_func = DiceLoss()\n",
        "    elif args.loss == 'crossentropy':\n",
        "        loss_func = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
        "    max_miou = 0\n",
        "    step = 0\n",
        "    for epoch in range(args.num_epochs):\n",
        "        lr = poly_lr_scheduler(optimizer, args.learning_rate, iter=epoch, max_iter=args.num_epochs)\n",
        "        model.train()\n",
        "        tq = tqdm(total=len(dataloader_train) * args.batch_size)\n",
        "        tq.set_description('epoch %d, lr %f' % (epoch, lr))\n",
        "        loss_record = []\n",
        "        for i, (data, label) in enumerate(dataloader_train):\n",
        "            print(f'data: {data}')\n",
        "            print(f'label: {label}')\n",
        "            data = data.cuda()\n",
        "            label = label.long().cuda()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with amp.autocast():\n",
        "                output, output_sup1, output_sup2 = model(data)\n",
        "                loss1 = loss_func(output, label)\n",
        "                loss2 = loss_func(output_sup1, label)\n",
        "                loss3 = loss_func(output_sup2, label)\n",
        "                loss = loss1 + loss2 + loss3\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "            tq.update(args.batch_size)\n",
        "            tq.set_postfix(loss='%.6f' % loss)\n",
        "            step += 1\n",
        "            writer.add_scalar('loss_step', loss, step)\n",
        "            loss_record.append(loss.item())\n",
        "        tq.close()\n",
        "        loss_train_mean = np.mean(loss_record)\n",
        "        writer.add_scalar('epoch/loss_epoch_train', float(loss_train_mean), epoch)\n",
        "        print('loss for train : %f' % (loss_train_mean))\n",
        "        if epoch % args.checkpoint_step == 0 and epoch != 0:\n",
        "            import os\n",
        "            if not os.path.isdir(args.save_model_path):\n",
        "                os.mkdir(args.save_model_path)\n",
        "            torch.save(model.module.state_dict(),\n",
        "                       os.path.join(args.save_model_path, 'latest_dice_loss.pth'))\n",
        "\n",
        "        if epoch % args.validation_step == 0 and epoch != 0:\n",
        "            precision, miou = val(args, model, dataloader_val)\n",
        "            if miou > max_miou:\n",
        "                max_miou = miou\n",
        "                import os \n",
        "                os.makedirs(args.save_model_path, exist_ok=True)\n",
        "                torch.save(model.module.state_dict(),\n",
        "                           os.path.join(args.save_model_path, 'best_dice_loss.pth'))\n",
        "            writer.add_scalar('epoch/precision_val', precision, epoch)\n",
        "            writer.add_scalar('epoch/miou val', miou, epoch)"
      ],
      "metadata": {
        "id": "quVpMD_PSwJS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(params):\n",
        "    # basic parameters\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--num_epochs', type=int, default=300, help='Number of epochs to train for')\n",
        "    parser.add_argument('--epoch_start_i', type=int, default=0, help='Start counting epochs from this number')\n",
        "    parser.add_argument('--checkpoint_step', type=int, default=10, help='How often to save checkpoints (epochs)')\n",
        "    parser.add_argument('--validation_step', type=int, default=10, help='How often to perform validation (epochs)')\n",
        "    parser.add_argument('--dataset', type=str, default=\"Cityscapes\", help='Dataset you are using.')\n",
        "    parser.add_argument('--crop_height', type=int, default=720, help='Height of cropped/resized input image to network')\n",
        "    parser.add_argument('--crop_width', type=int, default=960, help='Width of cropped/resized input image to network')\n",
        "    parser.add_argument('--batch_size', type=int, default=32, help='Number of images in each batch')\n",
        "    parser.add_argument(\"--iter-size\", type=int, default=1, help=\"Accumulate gradients for ITER_SIZE iterations.\")\n",
        "    parser.add_argument('--context_path', type=str, default=\"resnet101\",\n",
        "                        help='The context path model you are using, resnet18, resnet101.')\n",
        "    parser.add_argument('--learning_rate', type=float, default=0.01, help='learning rate used for train')\n",
        "    parser.add_argument('--data', type=str, default='', help='path of training data')\n",
        "    parser.add_argument(\"--data-list\", type=str, default='/gdrive/MyDrive/data/Cityscapes/train.txt', help=\"Path to the file listing the images in the source dataset.\")\n",
        "    parser.add_argument(\"--data-list-val\", type=str, default='/gdrive/MyDrive/data/Cityscapes/val.txt', help=\"Path to the file listing the image in the test subset.\")\n",
        "    parser.add_argument('--num_workers', type=int, default=4, help='num of workers')\n",
        "    parser.add_argument('--num_classes', type=int, default=32, help='num of object classes (with void)')\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=250000, help=\"Number of training steps.\")\n",
        "    parser.add_argument('--cuda', type=str, default='0', help='GPU ids used for training')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='whether to user gpu for training')\n",
        "    parser.add_argument('--pretrained_model_path', type=str, default=None, help='path to pretrained model')\n",
        "    parser.add_argument('--save_model_path', type=str, default=None, help='path to save model')\n",
        "    parser.add_argument('--optimizer', type=str, default='rmsprop', help='optimizer, support rmsprop, sgd, adam')\n",
        "    parser.add_argument('--loss', type=str, default='crossentropy', help='loss function, dice or crossentropy')\n",
        "    parser.add_argument(\"--random-scale\", action=\"store_true\", help=\"Whether to randomly scale the inputs during the training.\")\n",
        "    parser.add_argument(\"--random-mirror\", action=\"store_true\", help=\"Whether to randomly mirror the inputs during the training.\")\n",
        "    parser.add_argument(\"--set-type\", type=str, default='train', help=\"choose adaptation set.\")\n",
        "\n",
        "    args = parser.parse_args(params)\n",
        "\n",
        "    input_size = ('{height}, {width}').format(height = args.crop_height, width = args.crop_width)\n",
        "    #img_mean = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "    img_mean=(128, 128, 128)\n",
        "\n",
        "    # create dataset and dataloader\n",
        "    train_path = [os.path.join(args.data, 'train'), os.path.join(args.data, 'val')]\n",
        "    train_label_path = [os.path.join(args.data, 'train_labels'), os.path.join(args.data, 'val_labels')]\n",
        "    test_path = os.path.join(args.data, 'test')\n",
        "    test_label_path = os.path.join(args.data, 'test_labels')\n",
        "    csv_path = os.path.join(args.data, 'class_dict.csv')\n",
        "    \n",
        "    # Define dataloaders\n",
        "    dataloader_train = DataLoader(cityscapesDataSet(train_path, args.data_list, \n",
        "                    max_iters=args.num_steps * args.iter_size * args.batch_size,\n",
        "                    crop_size=input_size,\n",
        "                    scale=args.random_scale, mirror=args.random_mirror, \n",
        "                    mean=img_mean),\n",
        "        batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
        "    \n",
        "    \n",
        "    dataloader_val = DataLoader(cityscapesDataSet(test_path, args.data_list_val,\n",
        "                  max_iters=args.num_steps * args.iter_size * args.batch_size,\n",
        "                  crop_size=input_size,\n",
        "                  scale=False, mirror=args.random_mirror, \n",
        "                  mean=img_mean),\n",
        "        batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
        "    \n",
        "    # build model\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = args.cuda\n",
        "    model = BiSeNet(args.num_classes, args.context_path)\n",
        "    if torch.cuda.is_available() and args.use_gpu:\n",
        "        model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "    # build optimizer\n",
        "    if args.optimizer == 'rmsprop':\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), args.learning_rate)\n",
        "    elif args.optimizer == 'sgd':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), args.learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "    elif args.optimizer == 'adam':\n",
        "        optimizer = torch.optim.Adam(model.parameters(), args.learning_rate)\n",
        "    else:  # rmsprop\n",
        "        print('not supported optimizer \\n')\n",
        "        return None\n",
        "\n",
        "    # load pretrained model if exists\n",
        "    if args.pretrained_model_path is not None:\n",
        "        print('load model from %s ...' % args.pretrained_model_path)\n",
        "        model.module.load_state_dict(torch.load(args.pretrained_model_path))\n",
        "        print('Done!')\n",
        "\n",
        "    # train\n",
        "    train(args, model, optimizer, dataloader_train, dataloader_val)\n",
        "\n",
        "    # val(args, model, dataloader_val, csv_path)"
      ],
      "metadata": {
        "id": "8X0hpXG5S0ta"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    params = [\n",
        "        '--num_epochs', '50',\n",
        "        '--learning_rate', '2.5e-2',\n",
        "        '--data', '/gdrive/MyDrive/data/Cityscapes',\n",
        "        '--num_workers', '8',\n",
        "        '--num_classes', '19',\n",
        "        '--cuda', '0',\n",
        "        '--batch_size', '5',\n",
        "        '--save_model_path', '/gdrive/MyDrive/Project_AML/Models/checkpoints_101_adam',\n",
        "        '--context_path', 'resnet101',  # set resnet18 or resnet101, only support resnet18 and resnet101\n",
        "        '--optimizer', 'adam',\n",
        "\n",
        "    ]\n",
        "    main(params)"
      ],
      "metadata": {
        "id": "ryuEeQcMS4R5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "673347d7-9c58-47a0-9293-8592406aa391"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/1250000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:   0%|          | 0/1250000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image before resize: <PIL.Image.Image image mode=RGB size=2048x1024 at 0x7F41D7E4D5D0>\n",
            "type crop_size: <class 'tuple'>\n",
            "image after resize: <PIL.Image.Image image mode=RGB size=720x960 at 0x7F41D7DDB8D0>\n",
            "label before resize: <PIL.PngImagePlugin.PngImageFile image mode=L size=2048x1024 at 0x7F41D7DE5E10>\n",
            "label after resize: <PIL.Image.Image image mode=L size=720x960 at 0x7F41D7E4D5D0>\n",
            "image as array: [[[32. 38. 32.]\n",
            "  [52. 54. 42.]\n",
            "  [80. 83. 60.]\n",
            "  ...\n",
            "  [13. 20. 16.]\n",
            "  [12. 19. 15.]\n",
            "  [12. 19. 16.]]\n",
            "\n",
            " [[35. 40. 32.]\n",
            "  [56. 59. 44.]\n",
            "  [86. 89. 64.]\n",
            "  ...\n",
            "  [12. 20. 16.]\n",
            "  [11. 19. 15.]\n",
            "  [12. 19. 16.]]\n",
            "\n",
            " [[41. 45. 34.]\n",
            "  [60. 63. 45.]\n",
            "  [89. 94. 67.]\n",
            "  ...\n",
            "  [12. 20. 15.]\n",
            "  [12. 20. 16.]\n",
            "  [11. 19. 15.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[41. 58. 52.]\n",
            "  [43. 59. 53.]\n",
            "  [45. 60. 54.]\n",
            "  ...\n",
            "  [32. 46. 41.]\n",
            "  [33. 46. 42.]\n",
            "  [33. 44. 41.]]\n",
            "\n",
            " [[41. 58. 52.]\n",
            "  [43. 59. 53.]\n",
            "  [45. 60. 54.]\n",
            "  ...\n",
            "  [33. 46. 42.]\n",
            "  [33. 46. 42.]\n",
            "  [34. 45. 42.]]\n",
            "\n",
            " [[41. 58. 52.]\n",
            "  [43. 59. 53.]\n",
            "  [45. 60. 54.]\n",
            "  ...\n",
            "  [31. 44. 41.]\n",
            "  [31. 45. 42.]\n",
            "  [32. 44. 41.]]]\n",
            "label as array: [[3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]]\n",
            "image before resize: <PIL.Image.Image image mode=RGB size=2048x1024 at 0x7F41D7DB2E10>\n",
            "type crop_size: <class 'tuple'>\n",
            "image before resize: <PIL.Image.Image image mode=RGB size=2048x1024 at 0x7F41D7DC3C10>\n",
            "type crop_size: <class 'tuple'>\n",
            "image after resize: <PIL.Image.Image image mode=RGB size=720x960 at 0x7F41D7DDA3D0>\n",
            "label before resize: <PIL.PngImagePlugin.PngImageFile image mode=L size=2048x1024 at 0x7F41D7DE4410>\n",
            "label after resize: <PIL.Image.Image image mode=L size=720x960 at 0x7F41D7DB2E10>\n",
            "image after resize: <PIL.Image.Image image mode=RGB size=720x960 at 0x7F41D7E1B990>\n",
            "label before resize: <PIL.PngImagePlugin.PngImageFile image mode=L size=2048x1024 at 0x7F41D7DAB350>\n",
            "image before resize: <PIL.Image.Image image mode=RGB size=2048x1024 at 0x7F41D7E4D5D0>\n",
            "image before resize: <PIL.Image.Image image mode=RGB size=2048x1024 at 0x7F41D7F324D0>\n",
            "image as array: [[[ 36.  49.  41.]\n",
            "  [ 34.  47.  40.]\n",
            "  [ 33.  45.  40.]\n",
            "  ...\n",
            "  [189. 206. 197.]\n",
            "  [187. 203. 193.]\n",
            "  [165. 176. 163.]]\n",
            "\n",
            " [[ 36.  49.  40.]\n",
            "  [ 35.  47.  39.]\n",
            "  [ 34.  46.  41.]\n",
            "  ...\n",
            "  [189. 206. 197.]\n",
            "  [185. 202. 192.]\n",
            "  [168. 177. 164.]]\n",
            "\n",
            " [[ 39.  53.  42.]\n",
            "  [ 37.  49.  41.]\n",
            "  [ 35.  47.  41.]\n",
            "  ...\n",
            "  [190. 208. 197.]\n",
            "  [184. 201. 193.]\n",
            "  [170. 178. 166.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 89. 106.  92.]\n",
            "  [ 88. 106.  92.]\n",
            "  [ 88. 106.  90.]\n",
            "  ...\n",
            "  [ 71.  85.  67.]\n",
            "  [ 69.  84.  65.]\n",
            "  [ 67.  82.  67.]]\n",
            "\n",
            " [[ 89. 106.  92.]\n",
            "  [ 88. 106.  92.]\n",
            "  [ 88. 106.  90.]\n",
            "  ...\n",
            "  [ 75.  89.  71.]\n",
            "  [ 74.  88.  69.]\n",
            "  [ 72.  86.  71.]]\n",
            "\n",
            " [[ 89. 106.  92.]\n",
            "  [ 88. 106.  92.]\n",
            "  [ 88. 106.  90.]\n",
            "  ...\n",
            "  [ 73.  87.  71.]\n",
            "  [ 73.  87.  70.]\n",
            "  [ 73.  85.  70.]]]\n",
            "type crop_size: <class 'tuple'>\n",
            "type crop_size: <class 'tuple'>\n",
            "image before resize: <PIL.Image.Image image mode=RGB size=2048x1024 at 0x7F41D7E4D5D0>\n",
            "image before resize: <PIL.Image.Image image mode=RGB size=2048x1024 at 0x7F41D7DAAC50>\n",
            "label as array: [[3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]]type crop_size: <class 'tuple'>\n",
            "type crop_size: <class 'tuple'>\n",
            "image before resize: <PIL.Image.Image image mode=RGB size=2048x1024 at 0x7F41D7E4D5D0>\n",
            "\n",
            "image before resize: <PIL.Image.Image image mode=RGB size=2048x1024 at 0x7F41D7DBFED0>\n",
            "type crop_size: <class 'tuple'>\n",
            "type crop_size: <class 'tuple'>\n",
            "label after resize: <PIL.Image.Image image mode=L size=720x960 at 0x7F41D7DADC90>\n",
            "image after resize: <PIL.Image.Image image mode=RGB size=720x960 at 0x7F41D7DCBA50>\n",
            "label before resize: <PIL.PngImagePlugin.PngImageFile image mode=L size=2048x1024 at 0x7F41D7DE5ED0>\n",
            "image as array: [[[  7.  31.  69.]\n",
            "  [ 13.  32.  62.]\n",
            "  [ 19.  34.  54.]\n",
            "  ...\n",
            "  [ 77.  85.  84.]\n",
            "  [123. 120. 130.]\n",
            "  [ 61.  90. 108.]]\n",
            "\n",
            " [[  6.  12.  38.]\n",
            "  [ 10.  20.  40.]\n",
            "  [ 17.  27.  39.]\n",
            "  ...\n",
            "  [ 78.  87.  85.]\n",
            "  [122. 120. 129.]\n",
            "  [ 61.  91. 108.]]\n",
            "\n",
            " [[ 37.  40.  63.]\n",
            "  [ 35.  39.  58.]\n",
            "  [ 34.  39.  51.]\n",
            "  ...\n",
            "  [ 78.  88.  87.]\n",
            "  [120. 119. 129.]\n",
            "  [ 62.  91. 109.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 48.  54.  42.]\n",
            "  [ 47.  54.  42.]\n",
            "  [ 49.  55.  41.]\n",
            "  ...\n",
            "  [ 31.  38.  38.]\n",
            "  [ 38.  46.  39.]\n",
            "  [ 45.  52.  41.]]\n",
            "\n",
            " [[ 48.  54.  42.]\n",
            "  [ 47.  54.  42.]\n",
            "  [ 49.  55.  42.]\n",
            "  ...\n",
            "  [ 29.  37.  37.]\n",
            "  [ 30.  38.  37.]\n",
            "  [ 42.  49.  40.]]\n",
            "\n",
            " [[ 48.  54.  42.]\n",
            "  [ 47.  54.  42.]\n",
            "  [ 49.  55.  42.]\n",
            "  ...\n",
            "  [ 28.  37.  37.]\n",
            "  [ 28.  36.  37.]\n",
            "  [ 28.  37.  37.]]]image after resize: <PIL.Image.Image image mode=RGB size=720x960 at 0x7F41D7DDC150>\n",
            "\n",
            "image after resize: <PIL.Image.Image image mode=RGB size=720x960 at 0x7F41D7DDF210>\n",
            "label before resize: <PIL.PngImagePlugin.PngImageFile image mode=L size=2048x1024 at 0x7F41D7DE5690>\n",
            "label as array: [[3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]]image after resize: <PIL.Image.Image image mode=RGB size=720x960 at 0x7F41D7DDB550>\n",
            "label before resize: <PIL.PngImagePlugin.PngImageFile image mode=L size=2048x1024 at 0x7F41D7E22250>\n",
            "\n",
            "label before resize: <PIL.PngImagePlugin.PngImageFile image mode=L size=2048x1024 at 0x7F41D7DE3A90>\n",
            "label after resize: <PIL.Image.Image image mode=L size=720x960 at 0x7F41D7F324D0>\n",
            "image after resize: <PIL.Image.Image image mode=RGB size=720x960 at 0x7F41D7DADD90>\n",
            "image after resize: <PIL.Image.Image image mode=RGB size=720x960 at 0x7F41D7DADF50>\n",
            "label before resize: <PIL.PngImagePlugin.PngImageFile image mode=L size=2048x1024 at 0x7F41D7DE7310>\n",
            "label before resize: <PIL.PngImagePlugin.PngImageFile image mode=L size=2048x1024 at 0x7F41D7DAB090>\n",
            "label after resize: <PIL.Image.Image image mode=L size=720x960 at 0x7F41D7DDEC10>\n",
            "image as array: [[[190. 219. 212.]\n",
            "  [191. 219. 213.]\n",
            "  [191. 217. 212.]\n",
            "  ...\n",
            "  [ 12.  18.  14.]\n",
            "  [ 12.  19.  14.]\n",
            "  [ 13.  20.  15.]]\n",
            "\n",
            " [[191. 219. 212.]\n",
            "  [191. 219. 213.]\n",
            "  [192. 219. 213.]\n",
            "  ...\n",
            "  [ 12.  18.  14.]\n",
            "  [ 12.  19.  13.]\n",
            "  [ 14.  20.  14.]]\n",
            "\n",
            " [[191. 219. 212.]\n",
            "  [191. 218. 213.]\n",
            "  [192. 219. 213.]\n",
            "  ...\n",
            "  [ 13.  19.  14.]\n",
            "  [ 12.  18.  13.]\n",
            "  [ 13.  19.  14.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 37.  50.  42.]\n",
            "  [ 37.  50.  43.]\n",
            "  [ 37.  51.  43.]\n",
            "  ...\n",
            "  [ 44.  57.  43.]\n",
            "  [ 50.  64.  50.]\n",
            "  [ 55.  68.  55.]]\n",
            "\n",
            " [[ 37.  50.  42.]\n",
            "  [ 37.  50.  43.]\n",
            "  [ 37.  51.  43.]\n",
            "  ...\n",
            "  [ 41.  53.  41.]\n",
            "  [ 45.  57.  45.]\n",
            "  [ 50.  61.  50.]]\n",
            "\n",
            " [[ 37.  50.  42.]\n",
            "  [ 37.  50.  43.]\n",
            "  [ 37.  51.  43.]\n",
            "  ...\n",
            "  [ 39.  49.  39.]\n",
            "  [ 40.  51.  41.]\n",
            "  [ 43.  53.  44.]]]\n",
            "label after resize: <PIL.Image.Image image mode=L size=720x960 at 0x7F41D7DAAC50>\n",
            "label as array: [[3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]]label after resize: <PIL.Image.Image image mode=L size=720x960 at 0x7F41D7E4D5D0>\n",
            "\n",
            "image as array: [[[ 96. 112.  98.]\n",
            "  [ 93. 110.  96.]\n",
            "  [ 86. 105.  88.]\n",
            "  ...\n",
            "  [230. 244. 227.]\n",
            "  [209. 212. 197.]\n",
            "  [160. 168. 151.]]\n",
            "\n",
            " [[ 96. 112.  98.]\n",
            "  [ 93. 110.  95.]\n",
            "  [ 87. 106.  89.]\n",
            "  ...\n",
            "  [201. 220. 201.]\n",
            "  [163. 178. 156.]\n",
            "  [123. 140. 120.]]\n",
            "\n",
            " [[ 96. 112.  98.]\n",
            "  [ 93. 110.  95.]\n",
            "  [ 88. 107.  90.]\n",
            "  ...\n",
            "  [158. 183. 166.]\n",
            "  [116. 141. 119.]\n",
            "  [ 92. 116.  95.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 70.  85.  68.]\n",
            "  [ 70.  85.  68.]\n",
            "  [ 63.  80.  65.]\n",
            "  ...\n",
            "  [ 50.  64.  50.]\n",
            "  [ 47.  62.  48.]\n",
            "  [ 43.  60.  48.]]\n",
            "\n",
            " [[ 71.  85.  69.]\n",
            "  [ 70.  85.  68.]\n",
            "  [ 64.  80.  65.]\n",
            "  ...\n",
            "  [ 59.  72.  56.]\n",
            "  [ 57.  70.  55.]\n",
            "  [ 53.  68.  54.]]\n",
            "\n",
            " [[ 71.  85.  69.]\n",
            "  [ 70.  85.  68.]\n",
            "  [ 64.  80.  65.]\n",
            "  ...\n",
            "  [ 62.  74.  59.]\n",
            "  [ 62.  73.  59.]\n",
            "  [ 60.  73.  59.]]]\n",
            "label after resize: <PIL.Image.Image image mode=L size=720x960 at 0x7F41D7DAB790>\n",
            "label as array: [[3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]]label after resize: <PIL.Image.Image image mode=L size=720x960 at 0x7F41D7DBFED0>\n",
            "image as array: [[[50. 59. 46.]\n",
            "  [52. 62. 49.]\n",
            "  [56. 65. 52.]\n",
            "  ...\n",
            "  [60. 63. 42.]\n",
            "  [57. 60. 40.]\n",
            "  [57. 60. 40.]]\n",
            "\n",
            " [[46. 55. 42.]\n",
            "  [50. 59. 47.]\n",
            "  [53. 63. 51.]\n",
            "  ...\n",
            "  [58. 62. 40.]\n",
            "  [57. 60. 39.]\n",
            "  [56. 60. 40.]]\n",
            "\n",
            " [[37. 46. 35.]\n",
            "  [45. 54. 43.]\n",
            "  [49. 60. 47.]\n",
            "  ...\n",
            "  [57. 61. 40.]\n",
            "  [56. 59. 39.]\n",
            "  [56. 60. 39.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[20. 27. 22.]\n",
            "  [20. 27. 24.]\n",
            "  [20. 27. 23.]\n",
            "  ...\n",
            "  [34. 44. 36.]\n",
            "  [34. 45. 36.]\n",
            "  [37. 47. 40.]]\n",
            "\n",
            " [[20. 27. 22.]\n",
            "  [20. 27. 24.]\n",
            "  [20. 27. 23.]\n",
            "  ...\n",
            "  [33. 43. 37.]\n",
            "  [34. 44. 37.]\n",
            "  [35. 45. 37.]]\n",
            "\n",
            " [[20. 27. 22.]\n",
            "  [20. 27. 24.]\n",
            "  [20. 27. 23.]\n",
            "  ...\n",
            "  [30. 41. 36.]\n",
            "  [32. 41. 36.]\n",
            "  [34. 43. 37.]]]\n",
            "image as array: [[[132. 167. 100.]\n",
            "  [140. 173. 122.]\n",
            "  [149. 180. 147.]\n",
            "  ...\n",
            "  [  0.   0.   0.]\n",
            "  [  0.   0.   0.]\n",
            "  [  0.  16.   8.]]\n",
            "\n",
            " [[107. 148.   1.]\n",
            "  [123. 159.  28.]\n",
            "  [139. 171.  99.]\n",
            "  ...\n",
            "  [  0.   0.   0.]\n",
            "  [  0.   0.   0.]\n",
            "  [  0.  17.  10.]]\n",
            "\n",
            " [[131. 134.  21.]\n",
            "  [139. 151.  74.]\n",
            "  [152. 166. 122.]\n",
            "  ...\n",
            "  [  0.   0.   0.]\n",
            "  [  0.   0.   0.]\n",
            "  [  0.  18.  11.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 66.  79.  67.]\n",
            "  [ 65.  78.  67.]\n",
            "  [ 65.  77.  66.]\n",
            "  ...\n",
            "  [ 68.  79.  62.]\n",
            "  [ 68.  79.  65.]\n",
            "  [ 67.  78.  67.]]\n",
            "\n",
            " [[ 66.  79.  67.]\n",
            "  [ 65.  78.  67.]\n",
            "  [ 65.  77.  66.]\n",
            "  ...\n",
            "  [ 70.  80.  65.]\n",
            "  [ 70.  80.  65.]\n",
            "  [ 68.  79.  66.]]\n",
            "\n",
            " [[ 66.  79.  67.]\n",
            "  [ 65.  78.  67.]\n",
            "  [ 65.  77.  66.]\n",
            "  ...\n",
            "  [ 71.  80.  66.]\n",
            "  [ 71.  80.  66.]\n",
            "  [ 71.  80.  66.]]]\n",
            "\n",
            "label as array: [[3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]]\n",
            "label as array: [[3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]]\n",
            "image as array: [[[ 6. 11.  4.]\n",
            "  [ 8. 13.  6.]\n",
            "  [10. 14. 10.]\n",
            "  ...\n",
            "  [44. 41. 33.]\n",
            "  [ 3.  6.  0.]\n",
            "  [ 0. 10.  0.]]\n",
            "\n",
            " [[11. 14. 11.]\n",
            "  [10. 14. 12.]\n",
            "  [11. 15. 12.]\n",
            "  ...\n",
            "  [43. 40. 32.]\n",
            "  [ 2.  6.  0.]\n",
            "  [ 0. 12.  0.]]\n",
            "\n",
            " [[12. 15. 16.]\n",
            "  [12. 15. 15.]\n",
            "  [12. 15. 14.]\n",
            "  ...\n",
            "  [42. 39. 31.]\n",
            "  [ 2.  6.  0.]\n",
            "  [ 0. 13.  0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[58. 71. 64.]\n",
            "  [59. 71. 62.]\n",
            "  [58. 71. 61.]\n",
            "  ...\n",
            "  [56. 68. 62.]\n",
            "  [55. 68. 61.]\n",
            "  [55. 68. 61.]]\n",
            "\n",
            " [[58. 71. 64.]\n",
            "  [59. 71. 62.]\n",
            "  [58. 71. 61.]\n",
            "  ...\n",
            "  [55. 68. 61.]\n",
            "  [54. 67. 59.]\n",
            "  [54. 67. 59.]]\n",
            "\n",
            " [[58. 71. 64.]\n",
            "  [59. 71. 62.]\n",
            "  [58. 70. 61.]\n",
            "  ...\n",
            "  [55. 68. 60.]\n",
            "  [54. 66. 59.]\n",
            "  [54. 66. 59.]]]\n",
            "image as array: [[[108. 173.  81.]\n",
            "  [140. 191. 123.]\n",
            "  [166. 208. 162.]\n",
            "  ...\n",
            "  [152. 137. 134.]\n",
            "  [213. 186. 183.]\n",
            "  [206. 176. 172.]]\n",
            "\n",
            " [[ 47. 143.  10.]\n",
            "  [112. 175.  20.]\n",
            "  [157. 201.  81.]\n",
            "  ...\n",
            "  [150. 136. 132.]\n",
            "  [210. 182. 180.]\n",
            "  [202. 173. 169.]]\n",
            "\n",
            " [[206. 220.  95.]\n",
            "  [208. 225. 145.]\n",
            "  [211. 230. 181.]\n",
            "  ...\n",
            "  [148. 134. 130.]\n",
            "  [206. 179. 176.]\n",
            "  [198. 169. 165.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[128. 147. 140.]\n",
            "  [126. 146. 140.]\n",
            "  [127. 148. 140.]\n",
            "  ...\n",
            "  [ 31.  39.  36.]\n",
            "  [ 55.  68.  61.]\n",
            "  [ 83.  99.  90.]]\n",
            "\n",
            " [[128. 146. 140.]\n",
            "  [126. 146. 140.]\n",
            "  [127. 148. 140.]\n",
            "  ...\n",
            "  [ 33.  40.  35.]\n",
            "  [ 34.  41.  37.]\n",
            "  [ 77.  92.  84.]]\n",
            "\n",
            " [[128. 146. 140.]\n",
            "  [126. 146. 140.]\n",
            "  [127. 148. 140.]\n",
            "  ...\n",
            "  [ 36.  44.  39.]\n",
            "  [ 33.  41.  36.]\n",
            "  [ 34.  42.  37.]]]\n",
            "label as array: [[3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]]label as array: [[3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]\n",
            " [3. 3. 3. ... 3. 3. 3.]]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-16b258b0ef80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     ]\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-ef6f9c31684f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# val(args, model, dataloader_val, csv_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e1c694ef5f38>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, optimizer, dataloader_train, dataloader_val)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch %d, lr %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'data: {data}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'label: {label}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-19-73832f45813d>\", line 59, in __getitem__\n    for k, v in self.id_to_trainid.items():\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\", line 83, in __getattr__\n    raise AttributeError\nAttributeError\n"
          ]
        }
      ]
    }
  ]
}